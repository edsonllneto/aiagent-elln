from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.docstore.document import Document
import os

print("ğŸ“„ [1] Lendo arquivo de conhecimento...")
try:
    with open("conhecimento/conhecimento.txt", "r", encoding="utf-8") as f:
        conteudo = f.read()
except FileNotFoundError:
    print("âŒ Arquivo 'conhecimento/conhecimento.txt' nÃ£o encontrado.")
    exit(1)

print("ğŸ”ª [2] Dividindo texto em chunks...")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = text_splitter.split_text(conteudo)
print(f"ğŸ§© Total de chunks gerados: {len(chunks)}")

if not chunks:
    print("âš ï¸ Nenhum chunk foi gerado. Verifique o conteÃºdo do arquivo.")
    exit(1)

print("ğŸ“š [3] Convertendo chunks em documentos...")
docs = [Document(page_content=chunk) for chunk in chunks]

print("ğŸ§  [4] Gerando embeddings...")
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

print("ğŸ“¦ [5] Criando base vetorial FAISS...")
db = FAISS.from_documents(docs, embedding_model)

print("ğŸ’¾ [6] Salvando base em conhecimento/embeddings...")
save_path = "conhecimento/embeddings"
os.makedirs(save_path, exist_ok=True)
db.save_local(save_path)

print("âœ… Base de conhecimento gerada e salva com sucesso!")
